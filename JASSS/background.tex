
\section{Background}

The majority of poll results published before the Presidential Election
predicted Donald Trump's defeat 'by a landslide' \citep{pomarico_nate_2016}.
On Election Day, in spite of this, he secured more than enough electoral votes
to win him the presidency. What caused poll results to differ so significantly
from election results? The sole purpose of polls is to represent the voting
intentions of the population. Polling every eligible voter would require
unfathomable resources; as a result, all polls utilize only a sample of the
population. Unless pollsters fail to accurately sample from the voting
population, their results should be similar to the votes each candidate
receives. This issue came to light when Franklin D. Roosevelt beat Alfred
Landon in the 1936 Presidential election. Pollsters realized that by
conducting the poll explicitly over the phone, they were choosing to sample
from voters who could afford a house phone; they neglected to poll from an
accurate sample of the voting population. Since that election, pollsters have
aimed to not repeat that mistake. So what if there is a different effect at
work that caused poll results to significantly differ from election results?
What if people told pollsters their intentions were to vote against Trump,
but, on election day, voted for him?

\subsection{The Bradley Effect}


In 1982, the election for California's next governor was between Tom Bradley
and George Deukmejian. Bradley, long-time mayor of Los Angeles, was
African-American. Deukmejian was Caucasian. Bradley led the opinion polls
throughout the election; naturally, everyone assumed he would win. However,
once the votes were counted, Deukmejian was revealed the winner.

After Bradley's shocking loss, California residents wondered why the poll
results differed from the election results. One theory persisted: people must
have lied to pollsters. The ``Bradley Effect (BE)," as it is now commonly
known, is the ``notion that voters overstate their support for a black
candidate to pollsters for fear of being perceived as racist"
\citep{daprile_shattering_2008}. In the early 1990s, Harvard political
scientist Dan Hopkins studied the Bradley Effect by conducting a large-scale
empirical study on it over many different elections. He claimed that the BE
had a significant effect on the polls. He observed its negative effect on
black candidates and reported a median gap (\textit{i.e.} difference between
polls and results) of 3.1 percentage points. However, after 1996, he found no
evidence of the BE influencing any elections and reported a median gap of -0.3
percentage points. Some speculated the Bradley Effect might have been at work
against Barack Obama in the 2008 Presidential Election. Not only was he an
African American running against a Caucasian, but he was the candidate leading
in opinion polls. Nevertheless, he ended up winning both presidential
elections he ran in. Empirical evidence of the Bradley Effect rests on
individual cases. While typically the BE is found to result in the
African-American candidate losing, it was observed to have the opposite effect
on the NYC 1989 mayor race. David Dinkins, an African-American candidate, was
leading by a few percentage points against Ed Koch, the Caucasian incumbent,
in the weeks leading up to the election. He ended up winning the election by
over 8 percentage points despite the opinion polls suggesting a close race.
There is mixed evidence to support the influence the Bradley Effect can have
over any type of election. Gary Langer, the director of polling for ABC news,
believes the BE to be ``a theory in search of data"
\citep{wang_disappearing_2008}. The Bradley
Effect is explicitly about race. However, more generally, polled voters may be
dishonest to pollsters for a variety of other reasons having to do with the
perceived social stigma of supporting a certain candidate. In research, we can
generalize the BE to all situations in which the bias exits.


\subsection{Social Desirability Bias}
        
Social psychologists have long been interested in understanding why people lie to their friends and family about their true beliefs. They speculate that some people would prefer to lie about their opinions than face judgment or rejection from a close associate.

\textbf{Social desirability bias} is a term for the idea that the ``basic
human tendency to present oneself in the best possible light can significantly
distort the information gained from self-reports"
\citep{maccoby_interview_1954}.
People are often unwilling to truthfully report their beliefs on ``sensitive
topics for ego-defensive or impression management reasons." Maccoby and
Maccoby determined in 1954 that data collected from self-reports is
``systematically biased toward the respondent's perceptions of what is
socially acceptable." This phenomenon has been found to occur in ``virtually
all types of self-report measures and across nearly all social sciences
literatures."


\subsection{The 2016 U.S. Presidential Election}


The election for the 45th President of the United States took place on
November 7, 2016. Over 138 million people visited a polling booth that day to
submit a ballot. While there were many candidates on the ballot, by far most
voted for Hillary Clinton and Donald Trump. Clinton, the Democratic nominee,
is a former Secretary of State, Senator, and First Lady. Trump, the Republican
nominee, is an American businessman, television personality, and politician. 

Both candidates faced potential charges during their campaign that could have
prevented them from being elected. For instance, Clinton was being
investigated for emailing classified information through an unsecure, private
server while she was the Secretary of State; however, the FBI dropped the
investigation, stating ``no charges are appropriate in this case". Trump faced
multiple allegations of sexual assault, but was never formally charged.

While many people supported their candidate by publicly advocating for them,
some people felt pressure not to. This was especially true of Donald Trump.
Many of his supporters refused to express their voting intentions, because
they either felt it would turn away their Democratic friends and colleagues or
they would be ``seen as culturally insensitive" \cite{simmons_for_2017}; also
see \citep{shepard_gop_2016}. During the campaign, the majority of opinion
polls predicted Clinton would win the election. Nate Silver, a political
analyst who accurately predicted how 49 states would vote in the 2008
election, announced in his final election forecast that Clinton was a ``71\%
favorite" in polls. Alan Abramowitz, a political scientist and author, wrote
that ``Clinton is heading for a decisive victory over Donald Trump based on
national and swing state polls" \citep{abramowitz_history_2016}. The HuffPost
Presidential Forecast Model determined Clinton had a ``98.2\% chance of
winning," while Trump had ``no path to an Electoral College victory"
\citep{jackson_huffpost_2016}. The model projected Clinton garnering 323
electoral votes and a shift in the Senate to a Democratic majority. Trump's
campaign manager, Kellyanne Conway, was among the first to publicly speculate
that opinion polls weren't accurately reflecting the amount of support Trump
had. In an interview with UK ``Channel 4" news, she stated that ``it's become
socially desirable -- especially if you're a college-educated person in the
United States of America -- to say that you're against Donald Trump"
\citep{wright_donald_2016}. According to the campaign's research, Trump
``performs consistently better in online polling."

The only major poll to predict Trump's win was the Daybreak Poll conducted by
the LA Times. Based on an Internet probability survey, participants were
sampled from an ongoing UAS (Understanding America Study) panel of 6,000
randomly selected U.S. residents. Selected residents who lacked Internet
access were provided with some. Every day pollsters asked 1/7th of their
participants three questions: 1) How likely are you to vote? 2) Which
candidate do you think would win if the election was today? 3) Which candidate
would you vote for if the election was today? The pollsters discovered that
while more of the participants thought Clinton would win, most actually
planned on voting for Trump. Their approach differed from other polls in that
they adjusted their data so it would represent the diversity of the
population. There is good evidence to support the idea that for many Trump
supporters their voting intentions differed from the ones they communicated to
pollsters. Surely, this is not the first example of this phenomenon. The goal
of my study was to model this more complex decision-making process and
determine the extent to which it accurately predicts real-world political
outcomes.

