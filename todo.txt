This Week (Due by 7/1):
-----------------------
Hannah:
 * Continue to read papers in the "hannah to read" Zotero folder, and point
   out aggressively to Stephen specific papers he needs to read in order to
   not be a total loser on this project.
 * Social psychology: talk to Kolar for key terms
    - how many people can a node reasonably recieve information from?
    - how much time does a user spend looking through their timeline?
    - is there a positive correlation between number of tweets per day and amount time
      spent reading one's timeline?
    - do people get stubborn over time? is that correlated to echo-chamberness? 
 * Sim.opinion.dynamics()
    - reproduce lit search models
    - probability of converting: inversely proportional to victim's in-degree
    - group influence (reading HK paper and figuring out whether we're
        compatible at all with the way they do it)
    - Double check Holley 1975 (through Yildiz) & Clifford 1973 -- do they
        choose voters randomly each time step, or cycle through all? And does it
        matter?
        "At each date, some randomly chosen individual observes or communicates with 
        one of her neighbors and adopts her opinion." (Yildiz 2)
        "At each Poisson arrival, she chooses one of her neighbors uniformly" (Yildiz 5)
    - stubbornness: continuous
    - vector of opinions
        * binary
        * continuous
        * correlated opinions. (generate with mvnorm and then clip to (0,1) interval?)
 * Lit Search
    - vector of continuous opinions
    - dynamic graphs
    - Find the freaking "Stephen model," if it exists: i.e., there are n
      subjects, and the probability I'm influenced by you on subject k is
      related to how much we agree on the others. (Note this is NOT Sirbus
      2013, because in theirs, the opinions on a subject have norm 1. In
      Stephen's they are independent.)

Stephen:
 * Start the simulation with initial condition = Dave's political blog & book graph
 * Read at least some of the papers in the "stephen to read" Zotero folder.
 * Sim.opinion.dynamics()
    - Reproduce Vasquez & SR 2004
    - Implement Dave's experiment: 
        - add code for edge addition and deletion, appropriately parameterized
        - Never change opinions (!)
        - When you encounter a neighbor:
            - if you agree, have victim add an edge to a random influencer's
              neighbor (FOAF)  (note: EVEN if that neighbor doesn't agree.)
            - if you disagree, break the edge
    Dave is "morally certain" that this will "converge" to disconnected
    all-blue and all-red halves.
    - analyze
        * Confirm/deny that Holley's original does in fact converge less rapidly 
            than Zontine's.
        * Confirm/deny whether it matters that Holley chooses victim first,
            whereas we choose influencer first?
        * Do barbell graph with binary: can we get non-uniform equilibrium ever? (If
            graph is connected?) Dave thinks yes, Stephen boldly predicts no.
 * Data collection
    - Kick off process to grab last n tweets (n=20?) of all users in the
      Pelosi/Ryan graph and store in DB.

Due by 7/8:
------------
Hannah:
 * Read chapter 7 of K&C 

Stephen:
 * Read chapter 7 of K&C 


Due by 7/15:
------------
Hannah:
 * Read chapter 8 of K&C 

Stephen:
 * Read chapter 8 of K&C 


By the end of SSI (7/20):
-------------------------------------------
Hannah:
 * Poster and Powerpoint presentation
 * Read chapter 9 of K&C 

Stephen:
 * Read chapter 9 of K&C 
 * Final analysis, including parameter sweep of final assortavity/mean/SD vs
     a) bounded confidence
     b) num.encounter.per.iter
     c) migration factor
     d) number of connections




~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Tools/environment:
------------------


Background knowledge:
---------------------

Kolaczyk/Csardi book
Play with data mining classification. (wait for Stephen on this)


Lit search:
-----------

Begin a hierarchical outline in which you concisely describe all the lit
you've found. This is essentially the main product of all the searching and
reading you've done, and will become the seed of a Related Work section. This
outline is probably already partially reflected in the Zotero folder hierarchy
we've created as we've worked on this. The main difference is that now it will
be explicitly articulated rather than implicit in the organizational structure
of the documents. It should answer the questions, "so, what work has been done
in this area? What are the main findings? Where are the gaps?"


"Cornerstones":

Dynamic (evolving) networks. How are they represented? What graph invariants
are used for them?

Sentiment analysis: auto-classifying text as "liberal" or "conservative."
(There's just got to be stuff for this. Maybe there's even stuff for Tweets
specifically??)

"opinion dynamics." Also, "bounds of confidence," which seems to mean "agents
being influenced by other agents only to the degree that they have some level
of confidence in them."


"Competitors":

Find everything you can on measuring political polarization (or, if nothing
specific to that, *any* kind of polarization / attribute assortativity) in
social networks

Find everything you can on the effect of "crusader nodes"; i.e., how much
effect can nodes have that are deliberately introduced into a social network?
(Tough to know in advance what the terms will be, but I would think there has
to be stuff on this. Basically, the degree of influence of particular nodes,
and estimating how much a graph would change by the presence of a new node
with particular properties.)
Simulations of evolving graphs which form and delete edges based on homophily.
What are the principal findings here?


Synthetic data:
---------------

Get the baseline version of Stephen's code running.

Reproduce (what we believe are) canonical results:
    - binary ideology
        - each interaction, some probability of flipping to interacting
          agent's opinion
            a) interact uniformly with all other agents: converge to uniform
            opinion
		- who converges to who? is that random too?
            b) interact on social network only with neighbors: converge to
            clustered opinions

Do a parameter sweep of final assortativity vs. (a) closeness.threshold, (b)
num.encounters.per.iter, and (b) number of vertices.

Analyze other things besides assortativity. (Clustering coefficient comes to
mind, as does figuring out which nodes have highest centrality at the end --
are they the most moderate, or the most extreme, or is this unrelated?)

Add code for vertex ideology update, appropriately parameterized.

Add code for edge deletion, appropriately parameterized.

Add code to make encounters influenced by current neighbors. (i.e., don't just
choose encounter partners randomly from overall pop)

Start the sim with initial condition = Dave's political blog graph (and book
graph)



Real data:
----------

Load and explore Dave's political blog graphs (see github data folder)

Here's a good task: compute the attribute assortativity on both graphs, using
"value" as the attribute, to get an estimate of the "polarization" of the
graph.


Do a reboot in your mind about "what are all the ways we can get data from
Twitter?" (e.g., all tweets from user X? all followers/followees of user X?
all tweets with certain text match? streaming API? is there a time frame
(like, any tweets older than t won't be available)?


Do a reboot in your mind of "what are all the interpretations we might assign
to an edge in a Twitter graph?" follower/followee? mentions? something else?


Do some thinking and Googling and exploring Twitter, and consider the
question: "what's the best way for us to get a manageable but 'real' subset of
Twitter users who are reasonably well-connected to each other and who can
reliably be judged as 'liberal' or 'conservative'?"


Combining synthetic and real:
-----------------------------

1) Is the current Twitter graph sufficiently polarized to be hopeless (based
on what we know counts as 'hopeless' from the synthetic sim.)

2) Calibrate the initial conditions of the synthetic sim to match today's
Twitter graph, and then simulate from there. What is our forecast for the
actual Twitter graph "going polar," etc.?

3) Snapshot the real Twitter graph at two points in time, then simulate
starting from the first, and see what parameter settings (if any) produce
something like the second. That would tell us something about the underlying
data generating process (i.e., that would tell us something about how Twitter
users actually act.)
