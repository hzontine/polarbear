This Week (due by 6/10):
-------------------------------------
Hannah:
 * annotate the taxonomy.txt file with two things:
    1) the paper(s) that had results for each item
    2) a checkmark next to the things that sim.opinion.dynamics() supports.
 * schedule target due dates and owner (HZ or SD) for each specific piece of
   functionality we want to add to the sim.opinion.dynamics() code.
 * continue to add to outline.txt
 * Read first 1/3 of the papers in the "hannah to read" Zotero folder.
 * Read chapter 6 of K&C 
 * Synthetic
    - modify opinionDynamics.R to allow for ideologies to be continuous
    - analyze clustering coefficient
 * compute some basic graph metrics (transitivity, avg. path length, etc.) for
   the "small.RData" graph that SD collected by starting with the Hannah+Zach+
   Stephen+Rae+Lizzy seed set.
Stephen:
 * Get data collection code running on caladan.
 * Acquire at least one entire (small-ish) Twitter data set that we can use to
   calibrate the simulation.
 * Read first 1/3 of the papers in the "stephen to read" Zotero folder.
 * Read chapter 6 of K&C 



Due by the end of the 1st Summer Term (6/17):
--------------------------------------
Hannah:
 * Read second 1/3 of the papers in the "hannah to read" Zotero folder.
 * Continue to add and edit outline.txt
 * More Lit Search on Sentiment Analysis
    Find a political classifier
 * Synthetic
     - parameter sweep of final assortavity vs
         a) closeness.threshold
         b) num.encounter.per.iter
         c) num.vertices
     - add code for edge deletion, appropriately parameterized
 * Read chapter 10 of K&C 

Stephen:
 * Read second 1/3 of the papers in the "stephen to read" Zotero folder.
 * Synthetic
    - add code to represent ideologies as a vector of opinions, with each value
    reflecting a user's opinion on a certain "hot topic"
        * binary and continuous
 * Read chapter 10 of K&C 


Due by 6/24:
------------
Hannah:
 * Read last 1/3 of the papers in the "hannah to read" Zotero folder.
 * Read chapter 7 of K&C 

Stephen:
 * Read last 1/3 of the papers in the "stephen to read" Zotero folder.
 * Start the simulation with initial condition = Dave's political blog & book graph
 * Read chapter 7 of K&C 


Due by 7/1:
------------
Hannah:
 * Read chapter 8 of K&C 

Stephen:
 * Read chapter 8 of K&C 


Due by 7/8:
------------
Hannah:
 * Read chapter 9 of K&C 

Stephen:
 * Read chapter 9 of K&C 


By the end of SSI (7/20):
-------------------------------------------
Hannah:
 * Poster and Powerpoint presentation



This Fall:
--------------
 * Play with data mining classification. (wait for Stephen on this)


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Tools/environment:
------------------


Background knowledge:
---------------------

Kolaczyk/Csardi book
Play with data mining classification. (wait for Stephen on this)


Lit search:
-----------

Begin a hierarchical outline in which you concisely describe all the lit
you've found. This is essentially the main product of all the searching and
reading you've done, and will become the seed of a Related Work section. This
outline is probably already partially reflected in the Zotero folder hierarchy
we've created as we've worked on this. The main difference is that now it will
be explicitly articulated rather than implicit in the organizational structure
of the documents. It should answer the questions, "so, what work has been done
in this area? What are the main findings? Where are the gaps?"


"Cornerstones":

Dynamic (evolving) networks. How are they represented? What graph invariants
are used for them?

Sentiment analysis: auto-classifying text as "liberal" or "conservative."
(There's just got to be stuff for this. Maybe there's even stuff for Tweets
specifically??)

"opinion dynamics." Also, "bounds of confidence," which seems to mean "agents
being influenced by other agents only to the degree that they have some level
of confidence in them."


"Competitors":

Find everything you can on measuring political polarization (or, if nothing
specific to that, *any* kind of polarization / attribute assortativity) in
social networks

Find everything you can on the effect of "crusader nodes"; i.e., how much
effect can nodes have that are deliberately introduced into a social network?
(Tough to know in advance what the terms will be, but I would think there has
to be stuff on this. Basically, the degree of influence of particular nodes,
and estimating how much a graph would change by the presence of a new node
with particular properties.)
Simulations of evolving graphs which form and delete edges based on homophily.
What are the principal findings here?


Synthetic data:
---------------

Get the baseline version of Stephen's code running.

Reproduce (what we believe are) canonical results:
    - binary ideology
        - each interaction, some probability of flipping to interacting
          agent's opinion
            a) interact uniformly with all other agents: converge to uniform
            opinion
		- who converges to who? is that random too?
            b) interact on social network only with neighbors: converge to
            clustered opinions

Do a parameter sweep of final assortativity vs. (a) closeness.threshold, (b)
num.encounters.per.iter, and (b) number of vertices.

Analyze other things besides assortativity. (Clustering coefficient comes to
mind, as does figuring out which nodes have highest centrality at the end --
are they the most moderate, or the most extreme, or is this unrelated?)

Add code for vertex ideology update, appropriately parameterized.

Add code for edge deletion, appropriately parameterized.

Add code to make encounters influenced by current neighbors. (i.e., don't just
choose encounter partners randomly from overall pop)

Start the sim with initial condition = Dave's political blog graph (and book
graph)



Real data:
----------

Load and explore Dave's political blog graphs (see github data folder)

Here's a good task: compute the attribute assortativity on both graphs, using
"value" as the attribute, to get an estimate of the "polarization" of the
graph.


Do a reboot in your mind about "what are all the ways we can get data from
Twitter?" (e.g., all tweets from user X? all followers/followees of user X?
all tweets with certain text match? streaming API? is there a time frame
(like, any tweets older than t won't be available)?


Do a reboot in your mind of "what are all the interpretations we might assign
to an edge in a Twitter graph?" follower/followee? mentions? something else?


Do some thinking and Googling and exploring Twitter, and consider the
question: "what's the best way for us to get a manageable but 'real' subset of
Twitter users who are reasonably well-connected to each other and who can
reliably be judged as 'liberal' or 'conservative'?"


Combining synthetic and real:
-----------------------------

1) Is the current Twitter graph sufficiently polarized to be hopeless (based
on what we know counts as 'hopeless' from the synthetic sim.)

2) Calibrate the initial conditions of the synthetic sim to match today's
Twitter graph, and then simulate from there. What is our forecast for the
actual Twitter graph "going polar," etc.?

3) Snapshot the real Twitter graph at two points in time, then simulate
starting from the first, and see what parameter settings (if any) produce
something like the second. That would tell us something about the underlying
data generating process (i.e., that would tell us something about how Twitter
users actually act.)
