
Action items:
-------------
- 1 hour left for Jurafsky MOOC
- 1 hour thinking about getting Twitter data
- twitter sentiment API
- check out synthetic.R
	tcltk doesn't download!
- lit search:
	- "Mixing Beliefs Among Interacting Systems": check out
	Works Cited section
- need to find a political classifier
- how easy is it to get the twitter handles for all members of Congress?
- is there a tool where you can input a past twitter names and the output
	is their twitter ID number?

Tools/environment:
------------------


Background knowledge:
---------------------

Kolaczyk/Csardi book

Sentiment Analysis -- Jurafsky MOOC (unit 3)
https://class.coursera.org/nlp/lecture


Play with data mining classification. (wait for Stephen on this)





Lit search:
-----------

Begin a hierarchical outline in which you concisely describe all the lit
you've found. This is essentially the main product of all the searching and
reading you've done, and will become the seed of a Related Work section. This
outline is probably already partially reflected in the Zotero folder hierarchy
we've created as we've worked on this. The main difference is that now it will
be explicitly articulated rather than implicit in the organizational structure
of the documents. It should answer the questions, "so, what work has been done
in this area? What are the main findings? Where are the gaps?"


"Cornerstones":

Dynamic (evolving) networks. How are they represented? What graph invariants
are used for them?

Sentiment analysis: auto-classifying text as "liberal" or "conservative."
(There's just got to be stuff for this. Maybe there's even stuff for Tweets
specifically??)

"opinion dynamics." Also, "bounds of confidence," which seems to mean "agents
being influenced by other agents only to the degree that they have some level
of confidence in them."


"Competitors":

Find everything you can on measuring political polarization (or, if nothing
specific to that, *any* kind of polarization / attribute assortativity) in
social networks

Find everything you can on the effect of "crusader nodes"; i.e., how much
effect can nodes have that are deliberately introduced into a social network?
(Tough to know in advance what the terms will be, but I would think there has
to be stuff on this. Basically, the degree of influence of particular nodes,
and estimating how much a graph would change by the presence of a new node
with particular properties.)
Simulations of evolving graphs which form and delete edges based on homophily.
What are the principal findings here?


Synthetic data:
---------------

Get the baseline version of Stephen's code running.

Reproduce (what we believe are) canonical results:
    - binary ideology
        - each interaction, some probability of flipping to interacting
          agent's opinion
            a) interact uniformly with all other agents: converge to uniform
            opinion
		- who converges to who? is that random too?
            b) interact on social network only with neighbors: converge to
            clustered opinions

Do a parameter sweep of final assortativity vs. (a) closeness.threshold, (b)
num.encounters.per.iter, and (b) number of vertices.

Analyze other things besides assortativity. (Clustering coefficient comes to
mind, as does figuring out which nodes have highest centrality at the end --
are they the most moderate, or the most extreme, or is this unrelated?)

Add code for vertex ideology update, appropriately parameterized.

Add code for edge deletion, appropriately parameterized.

Add code to make encounters influenced by current neighbors. (i.e., don't just
choose encounter partners randomly from overall pop)

Start the sim with initial condition = Dave's political blog graph (and book
graph)



Real data:
----------

Write down unambiguously "what our precise Twitter data needs are."
(HZ take a first cut.)

Load and explore Dave's political blog graphs (see github data folder)

Here's a good task: compute the attribute assortativity on both graphs, using
"value" as the attribute, to get an estimate of the "polarization" of the
graph.


Do a reboot in your mind about "what are all the ways we can get data from
Twitter?" (e.g., all tweets from user X? all followers/followees of user X?
all tweets with certain text match? streaming API? is there a time frame
(like, any tweets older than t won't be available)?


Do a reboot in your mind of "what are all the interpretations we might assign
to an edge in a Twitter graph?" follower/followee? mentions? something else?


Do some thinking and Googling and exploring Twitter, and consider the
question: "what's the best way for us to get a manageable but 'real' subset of
Twitter users who are reasonably well-connected to each other and who can
reliably be judged as 'liberal' or 'conservative'?"


Combining synthetic and real:
-----------------------------

1) Is the current Twitter graph sufficiently polarized to be hopeless (based
on what we know counts as 'hopeless' from the synthetic sim.)

2) Calibrate the initial conditions of the synthetic sim to match today's
Twitter graph, and then simulate from there. What is our forecast for the
actual Twitter graph "going polar," etc.?

3) Snapshot the real Twitter graph at two points in time, then simulate
starting from the first, and see what parameter settings (if any) produce
something like the second. That would tell us something about the underlying
data generating process (i.e., that would tell us something about how Twitter
users actually act.)
