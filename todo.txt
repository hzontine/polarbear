This Week (due by 6/24):
------------------------------------
Hannah:
 * Read second 1/3 of the papers in the "hannah to read" Zotero folder.
 * Social psychology: how many people can a node reasonably recieve information from?
    - how much time does a user spend looking through their timeline?
    - is there a positive correlation between number of tweets per day and amount time
      spent reading one's timeline?
    - do people get stubborn over time? is that correlated to echo-chamberness? 
 * Lit Search
    - Find a political classifier
    - vector of continuous opinions
    - dynamic graphs
 * R: Task View
    - is it worth the time to create a classifier? 
 * Sim.opinion.dynamics()
    - stubbornness: continuous
    - vector of opinions
        * binary
        * correlated opinions. (generate with mvnorm and then clip to (0,1) interval?)
 * Read chapter 7 of K&C 

Stephen:
 * Read first and second 1/3 of the papers in the "stephen to read" Zotero folder.
 * Sim.opinion.dynamics()
   - analyze
        - parameter sweep of final assortavity/mean/SD vs
            a) bounded confidence
            b) num.encounter.per.iter
            c) migration factor
            d) number of connections
 * Read chapter 7 of K&C


Due by 7/1:
------------
Hannah:
 * Read chapter 8 & 10 of K&C 
 * Read last 1/3 of the papers in the "hannah to read" Zotero folder.
 * Sim.opinion.dynamics()
    - vector of opinions: continuous
    - probability of converting: inversely proportional to victim's in-degree
    - group influence (reading HK paper and figuring out whether we're
        compatible at all with the way they do it)
    - add code for edge addition and deletion, appropriately parameterized
Stephen:
 * Read chapter 8 & 10 of K&C 
 * Start the simulation with initial condition = Dave's political blog & book graph
 * Read last 1/3 of the papers in the "stephen to read" Zotero folder.

Due by 7/8:
------------
Hannah:
 * Read chapter 9 of K&C 

Stephen:
 * Read chapter 9 of K&C 


By the end of SSI (7/20):
-------------------------------------------
Hannah:
 * Poster and Powerpoint presentation



This Fall:
--------------
 * Play with data mining classification. (wait for Stephen on this)


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Tools/environment:
------------------


Background knowledge:
---------------------

Kolaczyk/Csardi book
Play with data mining classification. (wait for Stephen on this)


Lit search:
-----------

Begin a hierarchical outline in which you concisely describe all the lit
you've found. This is essentially the main product of all the searching and
reading you've done, and will become the seed of a Related Work section. This
outline is probably already partially reflected in the Zotero folder hierarchy
we've created as we've worked on this. The main difference is that now it will
be explicitly articulated rather than implicit in the organizational structure
of the documents. It should answer the questions, "so, what work has been done
in this area? What are the main findings? Where are the gaps?"


"Cornerstones":

Dynamic (evolving) networks. How are they represented? What graph invariants
are used for them?

Sentiment analysis: auto-classifying text as "liberal" or "conservative."
(There's just got to be stuff for this. Maybe there's even stuff for Tweets
specifically??)

"opinion dynamics." Also, "bounds of confidence," which seems to mean "agents
being influenced by other agents only to the degree that they have some level
of confidence in them."


"Competitors":

Find everything you can on measuring political polarization (or, if nothing
specific to that, *any* kind of polarization / attribute assortativity) in
social networks

Find everything you can on the effect of "crusader nodes"; i.e., how much
effect can nodes have that are deliberately introduced into a social network?
(Tough to know in advance what the terms will be, but I would think there has
to be stuff on this. Basically, the degree of influence of particular nodes,
and estimating how much a graph would change by the presence of a new node
with particular properties.)
Simulations of evolving graphs which form and delete edges based on homophily.
What are the principal findings here?


Synthetic data:
---------------

Get the baseline version of Stephen's code running.

Reproduce (what we believe are) canonical results:
    - binary ideology
        - each interaction, some probability of flipping to interacting
          agent's opinion
            a) interact uniformly with all other agents: converge to uniform
            opinion
		- who converges to who? is that random too?
            b) interact on social network only with neighbors: converge to
            clustered opinions

Do a parameter sweep of final assortativity vs. (a) closeness.threshold, (b)
num.encounters.per.iter, and (b) number of vertices.

Analyze other things besides assortativity. (Clustering coefficient comes to
mind, as does figuring out which nodes have highest centrality at the end --
are they the most moderate, or the most extreme, or is this unrelated?)

Add code for vertex ideology update, appropriately parameterized.

Add code for edge deletion, appropriately parameterized.

Add code to make encounters influenced by current neighbors. (i.e., don't just
choose encounter partners randomly from overall pop)

Start the sim with initial condition = Dave's political blog graph (and book
graph)



Real data:
----------

Load and explore Dave's political blog graphs (see github data folder)

Here's a good task: compute the attribute assortativity on both graphs, using
"value" as the attribute, to get an estimate of the "polarization" of the
graph.


Do a reboot in your mind about "what are all the ways we can get data from
Twitter?" (e.g., all tweets from user X? all followers/followees of user X?
all tweets with certain text match? streaming API? is there a time frame
(like, any tweets older than t won't be available)?


Do a reboot in your mind of "what are all the interpretations we might assign
to an edge in a Twitter graph?" follower/followee? mentions? something else?


Do some thinking and Googling and exploring Twitter, and consider the
question: "what's the best way for us to get a manageable but 'real' subset of
Twitter users who are reasonably well-connected to each other and who can
reliably be judged as 'liberal' or 'conservative'?"


Combining synthetic and real:
-----------------------------

1) Is the current Twitter graph sufficiently polarized to be hopeless (based
on what we know counts as 'hopeless' from the synthetic sim.)

2) Calibrate the initial conditions of the synthetic sim to match today's
Twitter graph, and then simulate from there. What is our forecast for the
actual Twitter graph "going polar," etc.?

3) Snapshot the real Twitter graph at two points in time, then simulate
starting from the first, and see what parameter settings (if any) produce
something like the second. That would tell us something about the underlying
data generating process (i.e., that would tell us something about how Twitter
users actually act.)
